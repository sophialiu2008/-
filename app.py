import streamlit as st
from dashscope import MultiModalConversation, Generation
from dashscope.audio.tts import SpeechSynthesizer # ğŸ‘ˆ æ–°å¢ï¼šé˜¿é‡Œè¯­éŸ³æœåŠ¡
import dashscope
from PIL import Image, ImageDraw, ImageFont
import tempfile
import os
import qrcode
import io
import requests
import docx
import PyPDF2

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å°å­¦ä½œæ–‡æ‰¹æ”¹ç²¾çµ", 
    page_icon="ğŸ“",
    layout="centered",
    initial_sidebar_state="expanded"
)

# CSS ç¾åŒ–
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stButton>button {
        width: 100%;
        border-radius: 20px;
        height: 50px;
        font-weight: bold;
    }
    .stSuccess {
        background-color: #f0fdf4;
        border-radius: 10px;
    }
    h1 {
        color: #FF4B4B;
        font-size: 2rem;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ“ å°å­¦ä½œæ–‡æ‰¹æ”¹ç²¾çµ")
st.caption("ğŸš€ æ”¯æŒ å›¾ç‰‡ / Word / PDF | æ™ºèƒ½åˆ†å¹´çº§ç‚¹è¯„ | çœŸäººè¯­éŸ³æœ—è¯»")

# --- 2. åŸºç¡€é…ç½® ---
api_key = st.secrets.get("DASHSCOPE_API_KEY")
if not api_key:
    st.error("âš ï¸ è¯·é…ç½® API Key")
    st.stop()
dashscope.api_key = api_key

if 'extracted_text' not in st.session_state:
    st.session_state.extracted_text = ""
if 'review_result' not in st.session_state:
    st.session_state.review_result = ""

# --- ğŸ› ï¸ å·¥å…·1ï¼šé˜¿é‡Œè¯­éŸ³åˆæˆ (é«˜éŸ³è´¨ç‰ˆ) ---
def generate_audio_dashscope(text, voice_name):
    # æ˜ å°„ç”¨æˆ·é€‰æ‹©çš„åå­—åˆ°é˜¿é‡Œæ¨¡å‹çš„ä»£ç 
    # å‚è€ƒæ–‡æ¡£ï¼šhttps://help.aliyun.com/document_detail/2702758.html
    voice_map = {
        "ğŸ‘©â€ğŸ« æ¸©æŸ”å¥³è€å¸ˆ (çŸ¥å¨)": "sambert-zhichu-v1",
        "ğŸ‘¨â€ğŸ« é˜³å…‰ç”·è€å¸ˆ (çŸ¥è¾¾)": "sambert-zhida-v1",
        "ğŸ‘§ å¯çˆ±ç«¥å£° (çŸ¥ç”œ)": "sambert-zhitian-v1",
        "ğŸ™ï¸ æ–°é—»æ’­æŠ¥ (çŸ¥å¦™)": "sambert-zhimiao-v1"
    }
    model_id = voice_map.get(voice_name, "sambert-zhichu-v1")
    
    try:
        # æ¸…æ´—æ‰ Markdown ç¬¦å·ï¼Œåªç•™çº¯æ–‡æœ¬
        text = text.replace("**", "").replace("###", "").replace("---", "")
        if len(text) > 1000: text = text[:1000] # é™åˆ¶é•¿åº¦
        
        # è°ƒç”¨é˜¿é‡Œ API
        result = SpeechSynthesizer.call(model=model_id, text=text, sample_rate=48000)
        
        if result.get_audio_data() is not None:
            with open("review.mp3", "wb") as f:
                f.write(result.get_audio_data())
            return True
        else:
            print(f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {result}")
            return False
    except Exception as e:
        st.warning(f"è¯­éŸ³æœåŠ¡æš‚æ—¶ç¹å¿™: {e}")
        return False

# --- ğŸ› ï¸ å·¥å…·2ï¼šä¸‹è½½å­—ä½“ ---
@st.cache_resource
def get_font():
    font_path = "SimHei.ttf"
    if not os.path.exists(font_path):
        url = "https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf"
        try:
            with st.spinner("é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½ä¸­æ–‡å­—ä½“..."):
                r = requests.get(url, timeout=30)
                if r.status_code == 200:
                    with open(font_path, "wb") as f:
                        f.write(r.content)
        except: return None 
    return font_path

# --- ğŸ› ï¸ å·¥å…·3ï¼šç”Ÿæˆå¡ç‰‡ ---
def create_review_card(text):
    font_path = get_font()
    width, height = 800, 1000
    img = Image.new('RGB', (width, height), color=(255, 255, 245))
    draw = ImageDraw.Draw(img)
    try:
        title_font = ImageFont.truetype(font_path, 40) if font_path else ImageFont.load_default()
        content_font = ImageFont.truetype(font_path, 24) if font_path else ImageFont.load_default()
    except:
        title_font = ImageFont.load_default()
        content_font = ImageFont.load_default()

    draw.text((40, 40), "ğŸ† ä½œæ–‡æ‰¹æ”¹æŠ¥å‘Š", fill=(255, 75, 75), font=title_font)
    draw.line((40, 100, 760, 100), fill=(200, 200, 200), width=2)
    
    margin, y_text = 40, 120
    lines = text.split('\n')
    for line in lines:
        line = line.replace('#', '').replace('*', '')
        if len(line) > 35: 
            for i in range(0, len(line), 35):
                chunk = line[i:i+35]
                draw.text((margin, y_text), chunk, fill=(50, 50, 50), font=content_font)
                y_text += 35
        else:
            draw.text((margin, y_text), line, fill=(50, 50, 50), font=content_font)
            y_text += 35
        if y_text > height - 100: break 
    draw.text((margin, height-60), "ğŸ¤– AI æ‰¹æ”¹åŠ©æ‰‹ç”Ÿæˆ", fill=(150, 150, 150), font=content_font)
    return img

# --- ğŸ› ï¸ å·¥å…·4ï¼šæ–‡ä»¶è§£æ ---
def read_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs])
def read_pdf(file):
    reader = PyPDF2.PdfReader(file)
    text = ""
    for page in reader.pages: text += page.extract_text() + "\n"
    return text
def stitch_images(image_list):
    if not image_list: return None
    images = [Image.open(x) for x in image_list]
    widths, heights = zip(*(i.size for i in images))
    new_im = Image.new('RGB', (max(widths), sum(heights)), (255, 255, 255))
    y_offset = 0
    for im in images: new_im.paste(im, (0, y_offset)); y_offset += im.size[1]
    return new_im

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # å¹´çº§
    grade = st.select_slider("é€‰æ‹©å¹´çº§", options=["ä¸€/äºŒå¹´çº§", "ä¸‰/å››å¹´çº§", "äº”/å…­å¹´çº§"], value="ä¸‰/å››å¹´çº§")
    
    # ğŸŒŸ æ–°åŠŸèƒ½ï¼šé€‰æ‹©è¯­éŸ³éŸ³è‰²
    voice_choice = st.selectbox(
        "ğŸ”Š é€‰æ‹©æœ—è¯»å£°éŸ³",
        ["ğŸ‘©â€ğŸ« æ¸©æŸ”å¥³è€å¸ˆ (çŸ¥å¨)", "ğŸ‘¨â€ğŸ« é˜³å…‰ç”·è€å¸ˆ (çŸ¥è¾¾)", "ğŸ‘§ å¯çˆ±ç«¥å£° (çŸ¥ç”œ)", "ğŸ™ï¸ æ–°é—»æ’­æŠ¥ (çŸ¥å¦™)"]
    )
    
    st.markdown("---")
    st.header("ğŸ“¤ ä¸Šä¼ ")
    uploaded_files = st.file_uploader("æ”¯æŒ å›¾ç‰‡ / Word / PDF", type=['png', 'jpg', 'jpeg', 'docx', 'pdf'], accept_multiple_files=True)
    
    st.markdown("---")
    app_url = "https://share.streamlit.io" 
    qr = qrcode.QRCode(box_size=5, border=2)
    qr.add_data(app_url)
    qr.make(fit=True)
    st.image(qr.make_image(fill='black', back_color='white').get_image(), caption="æ‰‹æœºæ‰«ç ä½¿ç”¨")

# --- 4. ä¸»é€»è¾‘ ---
if uploaded_files:
    file_type = uploaded_files[0].name.split('.')[-1].lower()
    
    # å›¾ç‰‡å¤„ç†
    if file_type in ['png', 'jpg', 'jpeg']:
        if len(uploaded_files) > 1:
            st.info(f"ğŸ“¸ æ‹¼æ¥ {len(uploaded_files)} å¼ å›¾ç‰‡...")
            image = stitch_images(uploaded_files)
        else:
            image = Image.open(uploaded_files[0])
        st.image(image, caption='é¢„è§ˆ', use_container_width=True)
        file_suffix = os.path.splitext(uploaded_files[0].name)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp_file:
            image.save(tmp_file)
            tmp_file_path = tmp_file.name

        if st.button("ğŸ” è¯†åˆ«æ–‡å­—", type="primary"):
            with st.spinner('ğŸ‘€ è¯†åˆ«ä¸­...'):
                try:
                    msg = [{'role': 'user', 'content': [{'image': f"file://{tmp_file_path}"}, {'text': 'OCRè¯†åˆ«ã€‚'}]}]
                    resp = MultiModalConversation.call(model='qwen-vl-max', messages=msg)
                    if resp.status_code == 200:
                        st.session_state.extracted_text = resp.output.choices[0].message.content[0]['text']
                        st.rerun()
                except Exception as e: st.error(f"é”™è¯¯: {e}")

    # æ–‡æ¡£å¤„ç†
    elif file_type in ['docx', 'pdf']:
        if st.button("ğŸ“– è¯»å–æ–‡æ¡£", type="primary"):
            try:
                if file_type == 'docx': st.session_state.extracted_text = read_docx(uploaded_files[0])
                else: st.session_state.extracted_text = read_pdf(uploaded_files[0])
                st.rerun()
            except Exception as e: st.error(f"è¯»å–å¤±è´¥: {e}")

    # æ‰¹æ”¹é€»è¾‘
    if st.session_state.extracted_text:
        st.markdown("### ğŸ“ ç¡®è®¤å†…å®¹")
        user_text = st.text_area("å†…å®¹", value=st.session_state.extracted_text, height=150)
        
        if st.button("âœ¨ æ™ºèƒ½æ‰¹æ”¹", type="primary"):
            with st.spinner('ğŸ¤– æ­£åœ¨æ‰¹æ”¹...'):
                s_prompt = "äº²åˆ‡é¼“åŠ±" if grade == "ä¸€/äºŒå¹´çº§" else "å®¢è§‚ä¸“ä¸š"
                prompt = f"ä½ æ˜¯è¯­æ–‡è€å¸ˆã€‚æ‰¹æ”¹{grade}ä½œæ–‡ã€‚è¯­æ°”ï¼š{s_prompt}ã€‚ä½œæ–‡ï¼š{user_text}ã€‚æŒ‰Markdownè¾“å‡ºï¼šäº®ç‚¹ã€è¯Šæ–­ã€å»ºè®®ã€è¯„çº§ã€‚"
                try:
                    resp = Generation.call(model='qwen-plus', messages=[{'role': 'user', 'content': prompt}])
                    if resp.status_code == 200:
                        st.session_state.review_result = resp.output.text
                        st.success("å®Œæˆï¼")
                    else: st.error("å¤±è´¥")
                except Exception as e: st.error(f"é”™è¯¯: {e}")

        # ç»“æœå±•ç¤º
        if st.session_state.review_result:
            st.markdown("---")
            st.markdown(st.session_state.review_result)
            
            st.markdown("### ğŸ åŠŸèƒ½åŒº")
            c1, c2 = st.columns(2)
            with c1:
                # ğŸŒŸ å‡çº§ç‚¹ï¼šè°ƒç”¨é˜¿é‡Œè¯­éŸ³
                if st.button("ğŸ”Š æ’­æ”¾è¯­éŸ³ç‚¹è¯„"):
                    with st.spinner(f"æ­£åœ¨ç”Ÿæˆ {voice_choice} çš„è¯­éŸ³..."):
                        if generate_audio_dashscope(st.session_state.review_result, voice_choice):
                            st.audio("review.mp3")
            with c2:
                img = create_review_card(st.session_state.review_result)
                buf = io.BytesIO()
                img.save(buf, format="PNG")
                st.download_button("ğŸ–¼ï¸ ä¸‹è½½è¯„è¯­å¡ç‰‡", data=buf.getvalue(), file_name="è¯„è¯­.png", mime="image/png")

else:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ–‡ä»¶")
