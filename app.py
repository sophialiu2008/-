import streamlit as st
from dashscope import MultiModalConversation, Generation
import dashscope
from PIL import Image
import io
import asyncio
import edge_tts
import nest_asyncio
import tempfile
import os

# è§£å†³ Streamlit ä¸­çš„å¼‚æ­¥å¾ªç¯é—®é¢˜
nest_asyncio.apply()

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="å°å­¦ä½œæ–‡æ™ºèƒ½æ‰¹æ”¹ Pro", page_icon="ğŸ“")
st.title("ğŸ“ å°å­¦ä½œæ–‡æ™ºèƒ½æ‰¹æ”¹ Pro")
st.markdown("### ğŸ“¸ æµç¨‹ï¼šæ‹ç…§ -> ç¡®è®¤æ–‡å­— -> æ™ºèƒ½æ‰¹æ”¹ + è¯­éŸ³æœ—è¯»")

# --- è·å– API Key ---
api_key = st.secrets.get("DASHSCOPE_API_KEY")
if not api_key:
    st.error("è¯·å…ˆåœ¨ Streamlit Secrets ä¸­é…ç½® DASHSCOPE_API_KEY")
    st.stop()
dashscope.api_key = api_key

# --- åˆå§‹åŒ– Session State (ç”¨æ¥â€œè®°ä½â€å˜é‡) ---
if 'ocr_result' not in st.session_state:
    st.session_state.ocr_result = ""
if 'review_result' not in st.session_state:
    st.session_state.review_result = ""

# --- è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆè¯­éŸ³ ---
async def text_to_speech(text, output_file="review.mp3"):
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    await communicate.save(output_file)

# --- ä¾§è¾¹æ ï¼šä¸Šä¼ å›¾ç‰‡ ---
with st.sidebar:
    st.header("1. ä¸Šä¼ ä½œæ–‡")
    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ ä½œæ–‡å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])

# --- ä¸»ç•Œé¢é€»è¾‘ ---
if uploaded_file is not None:
    # 1. å±•ç¤ºå›¾ç‰‡
    image = Image.open(uploaded_file)
    st.image(image, caption='å·²ä¸Šä¼ çš„ä½œæ–‡', use_container_width=True)
    
    # ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šå°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜ä¸ºæœ¬åœ°ä¸´æ—¶æ–‡ä»¶ï¼Œè·å–è·¯å¾„
    # å› ä¸º dashscope API éœ€è¦è¯»å–æœ¬åœ°è·¯å¾„ï¼Œä¸èƒ½ç›´æ¥è¯» streamlit çš„å¯¹è±¡
    file_suffix = os.path.splitext(uploaded_file.name)[1] # è·å–æ–‡ä»¶åç¼€ (.jpg ç­‰)
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name # æ‹¿åˆ°è¿™ä¸ªä¸´æ—¶æ–‡ä»¶çš„ç»å¯¹è·¯å¾„

    # 2. ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«æ–‡å­— (OCR)
    if st.button("ğŸ” ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«æ–‡å­—"):
        with st.spinner('æ­£åœ¨åŠªåŠ›è¾¨è®¤å­—è¿¹...'):
            try:
                # ä¸“é—¨çš„ Prompt è®©æ¨¡å‹åªåšè¯†åˆ«
                ocr_messages = [
                    {
                        "role": "system",
                        "content": [{"text": "ä½ æ˜¯ä¸€ä¸ªOCRåŠ©æ‰‹ã€‚è¯·å°†å›¾ç‰‡ä¸­çš„æ‰‹å†™ä½œæ–‡å®Œæ•´è½¬å½•ä¸ºæ–‡å­—ã€‚ä¸è¦è¿›è¡Œä¿®æ”¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯„è®ºï¼Œåªè¾“å‡ºè¯†åˆ«åˆ°çš„æ­£æ–‡å†…å®¹ã€‚"}]
                    },
                    {
                        "role": "user",
                        "content": [
                            # ğŸŒŸ è¿™é‡Œæ”¹æˆäº† file:// åŠ ä¸Šæœ¬åœ°è·¯å¾„
                            {"image": f"file://{tmp_file_path}"},
                            {"text": "è¯·è¯†åˆ«å›¾ä¸­çš„æ–‡å­—ã€‚"}
                        ]
                    }
                ]
                
                response = MultiModalConversation.call(model='qwen-vl-max', messages=ocr_messages)
                
                if response.status_code == 200:
                    raw_text = response.output.choices[0].message.content[0]['text']
                    st.session_state.ocr_result = raw_text 
                    st.success("è¯†åˆ«æˆåŠŸï¼è¯·åœ¨ä¸‹æ–¹æ ¸å¯¹ã€‚")
                else:
                    st.error(f"è¯†åˆ«å¤±è´¥: {response.message}")
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")

    # 3. ç¬¬äºŒæ­¥ï¼šäººå·¥æ ¡å¯¹
    if st.session_state.ocr_result:
        st.markdown("---")
        st.header("2. ç¡®è®¤æ–‡å­—å†…å®¹")
        st.info("å¦‚æœAIçœ‹é”™äº†ï¼Œè¯·åœ¨ä¸‹æ–¹ç›´æ¥ä¿®æ”¹ï¼Œç„¶åç‚¹å‡»æ‰¹æ”¹ã€‚")
        
        user_edited_text = st.text_area("ä½œæ–‡å†…å®¹", value=st.session_state.ocr_result, height=200)

        # 4. ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç‚¹è¯„
        if st.button("âœ¨ ç¡®è®¤æ— è¯¯ï¼Œå¼€å§‹æ‰¹æ”¹"):
            with st.spinner('è€å¸ˆæ­£åœ¨æ‰¹æ”¹ä¸­...'):
                grade_prompt = f"""
                ä½ æ˜¯ä¸€ä½äº²åˆ‡çš„å°å­¦è¯­æ–‡è€å¸ˆã€‚è¯·æ ¹æ®å­¦ç”Ÿä½œæ–‡å†…å®¹è¿›è¡Œæ‰¹æ”¹ã€‚
                
                **ä½œæ–‡å†…å®¹**ï¼š
                {user_edited_text}

                **æ‰¹æ”¹è¦æ±‚**ï¼ˆMarkdownæ ¼å¼ï¼‰ï¼š
                1. **ã€æš–å¿ƒç‚¹è¯„ã€‘**ï¼šå…ˆè‚¯å®šä¼˜ç‚¹ï¼ˆå¦‚â€œå­—è¿¹å·¥æ•´â€ã€â€œæƒ³è±¡åŠ›ä¸°å¯Œâ€ï¼‰ã€‚
                2. **ã€å­—è¯è¯Šæ‰€ã€‘**ï¼šæŒ‡å‡ºå…·ä½“çš„é”™åˆ«å­—ã€ç—…å¥ï¼Œå¹¶ç»™å‡ºä¿®æ”¹æ„è§ã€‚
                3. **ã€ä½³å¥æ‘˜æŠ„ã€‘**ï¼šæ‰¾å‡ºæ–‡ä¸­å†™å¾—å¥½çš„å¥å­ã€‚
                4. **ã€æå‡å»ºè®®ã€‘**ï¼šç»™å‡ºä¸€ä¸ªå…·ä½“çš„æ”¹è¿›æ–¹å‘ï¼ˆå¦‚â€œå¤šç”¨ä¸€äº›å½¢å®¹è¯â€ï¼‰ã€‚
                
                è¯­æ°”è¦æ¸©æŸ”ã€é¼“åŠ±ä¸ºä¸»ï¼Œé€‚åˆå°å­¦ç”Ÿé˜…è¯»ã€‚
                """
                
                try:
                    # ä½¿ç”¨ qwen-plus è¿›è¡Œçº¯æ–‡æœ¬æ‰¹æ”¹
                    response = Generation.call(model='qwen-plus', messages=[{'role': 'user', 'content': grade_prompt}])
                    
                    if response.status_code == 200:
                        review_content = response.output.text
                        st.session_state.review_result = review_content
                        st.success("æ‰¹æ”¹å®Œæˆï¼")
                    else:
                        st.error("æ‰¹æ”¹å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")

    # 5. ç¬¬å››æ­¥ï¼šå±•ç¤ºç»“æœä¸è¯­éŸ³
    if st.session_state.review_result:
        st.markdown("---")
        st.header("3. è€å¸ˆç‚¹è¯„")
        st.markdown(st.session_state.review_result)
        
        st.markdown("---")
        st.header("ğŸ”Š å¬è€å¸ˆè¯´")
        if st.button("æ’­æ”¾è¯­éŸ³ç‚¹è¯„"):
            with st.spinner("æ­£åœ¨åˆæˆè¯­éŸ³..."):
                asyncio.run(text_to_speech(st.session_state.review_result))
                st.audio("review.mp3")

else:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ä¸€å¼ ä½œæ–‡ç…§ç‰‡")
